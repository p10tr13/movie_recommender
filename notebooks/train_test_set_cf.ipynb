{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f74365",
   "metadata": {},
   "source": [
    "### Notebook dedicated to dividing data into training set and test set for the collaborative filtering method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c8ca34",
   "metadata": {},
   "source": [
    "#### Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9ab2f",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54773c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6569a05",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94933c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings in the set:  32000204\n",
      "Sample ratings:\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1       17     4.0  944249077\n",
      "1       1       25     1.0  944250228\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('../data/ratings.csv')\n",
    "print(\"Number of ratings in the set: \", ratings.shape[0])\n",
    "print(\"Sample ratings:\")\n",
    "print(ratings.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4dcb3a",
   "metadata": {},
   "source": [
    "#### Data division"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ea8b8",
   "metadata": {},
   "source": [
    "The data is divided according to the following rules:\n",
    "- 20% of the data is assigned to the test set\n",
    "- 80% of the data is assigned to the training set\n",
    "- this division is performed on the ratings of each user (stratification by users ensures that each user is represented in both sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3a7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    ratings,\n",
    "    test_size=0.2,\n",
    "    stratify=ratings[\"userId\"],\n",
    "    random_state=264,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbb0b6",
   "metadata": {},
   "source": [
    "As we can see in the code above, the seed is set to a fixed value so that the data is always divided in the same way.\n",
    "<br> The data division assumptions will be checked below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9aac2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 25600163 | Test: 6400041\n",
      "Percentage of users in the test set: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTrain: {len(train_data)} | Test: {len(test_data)}\")\n",
    "print(f\"Percentage of users in the test set: {test_data['userId'].nunique()/ratings['userId'].nunique():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29077cc6",
   "metadata": {},
   "source": [
    "Collaborative filtering will not be able to make accurate predictions for movies it has not been trained on, so only movies that are in the training set should be selected for our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a5208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_movies = set(train_data[\"movieId\"].unique())\n",
    "test_data_clean = test_data[test_data[\"movieId\"].isin(train_movies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83be496",
   "metadata": {},
   "source": [
    "Next, these deleted movies from the test set will be moved to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a913d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_test = test_data[~test_data[\"movieId\"].isin(train_movies)]\n",
    "final_train = pd.concat([train_data, missing_in_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab76ca0",
   "metadata": {},
   "source": [
    "Below are the results of changes in the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59214e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After correction:\n",
      "Final Train: 25604902\n",
      "Test Clean: 6395302\n",
      "Deleted from test: 4739\n",
      "Percentage of deleted: 0.074%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAfter correction:\")\n",
    "print(f\"Final Train: {len(final_train)}\")\n",
    "print(f\"Test Clean: {len(test_data_clean)}\")\n",
    "print(f\"Deleted from test: {len(test_data)-len(test_data_clean)}\")\n",
    "print(f\"Percentage of deleted: {(len(test_data)-len(test_data_clean))/len(test_data):.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87ff03",
   "metadata": {},
   "source": [
    "Next, our division will be verified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d40fd7",
   "metadata": {},
   "source": [
    "1. Are all movies in the test set also in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1d70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_data_clean[\"movieId\"].nunique() == test_data_clean[\"movieId\"].nunique(), \"Incorrect number of movies in the test set\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901eaa3",
   "metadata": {},
   "source": [
    "2. Are all users present in both sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6f8c42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Users in the training set: 200948\n",
      "Users in the test set:    200948\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nUsers in the training set: {final_train['userId'].nunique()}\")\n",
    "print(f\"Users in the test set:    {test_data_clean['userId'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63e71c",
   "metadata": {},
   "source": [
    "3. Were the ratings of individual users divided in a ratio of $1/5$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f16e036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First sample user: 1\n",
      "Trening: 113 ocen\n",
      "Test:    28 ocen\n",
      "\n",
      "Second sample user: 10\n",
      "Trening: 528 ocen\n",
      "Test:    132 ocen\n"
     ]
    }
   ],
   "source": [
    "sample_user1 = ratings['userId'].iloc[0]\n",
    "sample_user2 = ratings['userId'].iloc[1000]\n",
    "print(f\"\\nFirst sample user: {sample_user1}\")\n",
    "print(f\"Trening: {len(final_train[final_train['userId'] == sample_user1])} ocen\")\n",
    "print(f\"Test:    {len(test_data_clean[test_data_clean['userId'] == sample_user1])} ocen\")\n",
    "print(f\"\\nSecond sample user: {sample_user2}\")\n",
    "print(f\"Trening: {len(final_train[final_train['userId'] == sample_user2])} ocen\")\n",
    "print(f\"Test:    {len(test_data_clean[test_data_clean['userId'] == sample_user2])} ocen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e898df17",
   "metadata": {},
   "source": [
    "4. Sparsity of matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5569da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparsity Trening: 99.85%\n",
      "Sparsity Test: 99.94%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSparsity Trening: {(1 - len(final_train)/(final_train['userId'].nunique() * final_train['movieId'].nunique())):.2%}\")\n",
    "print(f\"Sparsity Test: {(1 - len(test_data_clean)/(test_data_clean['userId'].nunique() * test_data_clean['movieId'].nunique())):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7a7e7",
   "metadata": {},
   "source": [
    "Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffa3e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.to_csv('../data/cf/train_rating.csv', index=False)\n",
    "test_data_clean.to_csv('../data/cf/test_rating.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
